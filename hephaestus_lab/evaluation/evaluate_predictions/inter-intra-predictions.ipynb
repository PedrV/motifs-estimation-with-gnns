{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"/some/base/path/\")\n",
    "os.chdir(BASE)\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from verify_file import verify\n",
    "import hephaestus.utils.load_general_config as hconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/results/from/evaluate/some/folder/CORRECTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert verify(DATA_DIR / \"preds\" / \"nd_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+nd.csv\")\n",
    "df_nd_gin = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"nd_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+nd.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"nd_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+nd.csv\")\n",
    "df_nd_sage = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"nd_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+nd.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"d_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+d.csv\")\n",
    "df_d_gin = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"d_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+d.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "######################## Real ########################\n",
    "assert verify(DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+mlreal.csv\")\n",
    "df_d_gin_mlreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+mlreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+mlreal.csv\")\n",
    "df_nd_gin_mlreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+mlreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+mlreal.csv\")\n",
    "df_nd_sage_mlreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"mlreal_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+mlreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "# Small\n",
    "assert verify(DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+sreal.csv\")\n",
    "df_d_gin_sreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240121-203233+TorchTrainer_e9bc79c6+sreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+sreal.csv\")\n",
    "df_nd_gin_sreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240201-180351+TorchTrainer_d9c8c887+sreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")\n",
    "\n",
    "assert verify(DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+sreal.csv\")\n",
    "df_nd_sage_sreal = pd.read_csv(\n",
    "    DATA_DIR / \"preds\" / \"sreal_preds\" / \"TALOS_20240216-185022+TorchTrainer_995a1ad7+sreal.csv\",\n",
    "    usecols=[i for i in range(1, hconfig.NUM_SUBGRAPHS + 4)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_synt = {\n",
    "    \"sage\": df_nd_sage,\n",
    "    \"gin\": df_nd_gin,\n",
    "    \"d_gin\": df_d_gin,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='p1'/>\n",
    "\n",
    "## Sufficiently Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs_synt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_dataset_names_synt = {\n",
    "    \"nd3DGEOM_DD\": \"Geometric-3D DD\",\n",
    "    \"ndDD\": \"Duplication Divergence\",\n",
    "    \"ndEBA\": \"Extended Barabasi Albert\",\n",
    "    \"ndERDOS_RENYI\": \"Erdos-Renyi\",\n",
    "    \"ndFOREST_FIRE\": \"Forest Fire\",\n",
    "    \"ndGAUSSIAN_RP\": \"Gaussian Partition\",\n",
    "    \"ndLRANDOM_GEOMETRIC\": \"Random Geometric\",\n",
    "    \"ndNEWMAN_WATTS_STROGATZ\": \"Newman Watts Strogatz\",\n",
    "    \"ndPOWERLAW_CLUSTER\": \"Powerlaw Cluster\",\n",
    "    \"ndRANDOM_REGULAR\": \"Random Regular\",\n",
    "    \"ndWATTS_STROGATZ\": \"Watts Strogatz\",\n",
    "    \"dBALANCEDTREE\": \"Balanced Tree\",\n",
    "    \"dBARBELLGRAPH\": \"Barbell\",\n",
    "    \"dBINOMIALTREE\": \"Binomial Tree\",\n",
    "    \"dCHORDALCYCLE\": \"Chordal Cycle\",\n",
    "    \"dCIRCULARLADDER\": \"Circular Ladder\",\n",
    "    \"dDOROGOVTSEV_GOLTSEV_MENDES\": \"DGM Graph\",\n",
    "    \"dFULLRARYTREE\": \"Full Rary Tree\",\n",
    "    \"dGRID\": \"Square Lattice\",\n",
    "    \"dHEXAGONALLATTICE\": \"Hexagonal Lattice\",\n",
    "    \"dLOLLIPOP\": \"Lollipop\",\n",
    "    \"dSTARGRAPH\": \"Star\",\n",
    "    \"dTRIANGULARLATTICE\": \"Triangular Lattice\",\n",
    "}\n",
    "\n",
    "col_order_synt = [\n",
    "    \"Balanced Tree\",\n",
    "    \"Barbell Graph\",\n",
    "    \"Binomial Tree\",\n",
    "    \"Chordal Cycle Graph\",\n",
    "    \"Circular Ladder Graph\",\n",
    "    \"Dorogovtsev Goltsev Mendes Graph\",\n",
    "    \"Full Rary Tree\",\n",
    "    \"Square Lattice\",\n",
    "    \"Hexagonal Lattice Graph\",\n",
    "    \"Lollipop Graph\",\n",
    "    \"Star Graph\",\n",
    "    \"Triangular Lattice Graph\",\n",
    "    \"Extended Barabasi Albert Graph\",\n",
    "    \"Erdos-Renyi\",\n",
    "    \"Watts Strogatz Graph\",\n",
    "    \"Duplication Divergence Graph\",\n",
    "    \"Powerlaw Cluster Graph\",\n",
    "    \"Forest Fire\",\n",
    "    \"Gaussian Random Partition Graph\",\n",
    "    \"Newman Watts Strogatz Graph\",\n",
    "    \"Random Regular Graph\",\n",
    "    \"Geometric-3D DD Graph\",\n",
    "    \"Random Limited Geometric Graph\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(name_model):\n",
    "    print(f\"Starting {name_model}!\")\n",
    "    results_model = dfs_synt[name_model]\n",
    "\n",
    "    time_start = time.time()\n",
    "    all_graphs = results_model[\"GraphName\"].unique()\n",
    "\n",
    "    all_labels = results_model[\"DatasetName\"].unique() \n",
    "    N = len(all_labels)\n",
    "    matrix = pd.DataFrame(np.zeros((N, N), dtype=int), index=all_labels, columns=all_labels)\n",
    "\n",
    "    for i, name in enumerate(all_graphs):\n",
    "        _results_model = results_model[results_model[\"GraphName\"] == name]\n",
    "        generator = _results_model.iloc[0][\"DatasetName\"]\n",
    "\n",
    "        pred = _results_model[_results_model[\"Type\"] == \"Pred\"].to_numpy()[0][:-3]\n",
    "\n",
    "        min_diff = np.inf\n",
    "        min_cand_gen = \"\"\n",
    "        for candidate_name in results_model[\"GraphName\"].unique():\n",
    "            if candidate_name == name:\n",
    "                continue\n",
    "\n",
    "            candidate_name_results_model = results_model[results_model[\"GraphName\"] == candidate_name]\n",
    "            candidate_generator = candidate_name_results_model.iloc[0][\"DatasetName\"]\n",
    "\n",
    "            true = candidate_name_results_model[candidate_name_results_model[\"Type\"] == \"True\"].to_numpy()[0][:-3]\n",
    "\n",
    "            candidate_diff = np.mean(np.abs(true - pred))\n",
    "            if candidate_diff < min_diff:\n",
    "                min_diff = candidate_diff\n",
    "                min_cand_gen = candidate_generator\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            hours, remainder = divmod(time.time()-time_start, 3600)  # 3600 seconds in an hour\n",
    "            minutes, seconds = divmod(remainder, 60)       # 60 seconds in a minute\n",
    "            # Format the time as hours:minutes:seconds\n",
    "            formatted_time = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "            print(f\"Elapsed time: {formatted_time}, {i}/{len(all_graphs)}\")\n",
    "\n",
    "\n",
    "        matrix[generator][min_cand_gen] += 1\n",
    "\n",
    "    matrix.to_csv(f\"{name_model}.csv\")\n",
    "    return matrix\n",
    "\n",
    "matrices = []\n",
    "for model in dfs.keys():\n",
    "    print(model)\n",
    "    _m = most_similar(dfs[model])\n",
    "    matrices.append(_m)\n",
    "\n",
    "with open(\"matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(matrices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dgin = pd.read_csv(\"/results/from/evaluate/some/folder/d_gin.csv\", index_col=False)  # Change do DATA_DIR\n",
    "names = list(m_dgin.iloc[:,0])\n",
    "index_mapper = {i : pretty_dataset_names_synt[j] for i,j in enumerate(names)}\n",
    "m_dgin = m_dgin.iloc[:, 1:]\n",
    "index_mapper_cols = {i : pretty_dataset_names_synt[i] for i in m_dgin.columns}\n",
    "m_dgin.rename(index=index_mapper, inplace=True)\n",
    "m_dgin.rename(columns=index_mapper_cols, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    m_dgin, \n",
    "    annot=True,  # Show values\n",
    "    fmt=\"3d\",  # Format numbers to 2 decimal places\n",
    "    cmap=\"magma\",  # Color scheme (colorblind-friendly: \"coolwarm\", \"viridis\")\n",
    "    linewidths=0.5,  # Thin lines for separation\n",
    "    linecolor=\"black\",  # Subtle black grid lines\n",
    "    cbar_kws={'shrink': 0.75, 'aspect': 30},  # Shrink color bar to fit\n",
    "    square=True,  # Keep cells square-shaped,\n",
    "    cbar=False,\n",
    "    annot_kws={\"size\": 14},\n",
    ")\n",
    "\n",
    "# Improve label readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=14)  # Rotate x labels slightly\n",
    "plt.yticks(rotation=0, fontsize=14)  # Keep y labels horizontal\n",
    "ax.set(yticklabels=[])\n",
    "\n",
    "# Adjust title and labels\n",
    "# plt.title(\"GIN\", fontsize=18, pad=10, fontweight=\"bold\")  # Add title\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(\"dgin-heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gin = pd.read_csv(\"/results/from/evaluate/some/folder/gin.csv\", index_col=False)  # Change do DATA_DIR\n",
    "names = list(m_gin.iloc[:,0])\n",
    "index_mapper = {i : pretty_dataset_names_synt[j] for i,j in enumerate(names)}\n",
    "m_gin = m_gin.iloc[:, 1:]\n",
    "index_mapper_cols = {i : pretty_dataset_names_synt[i] for i in m_gin.columns}\n",
    "m_gin.rename(index=index_mapper, inplace=True)\n",
    "m_gin.rename(columns=index_mapper_cols, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    m_gin, \n",
    "    annot=True,  # Show values\n",
    "    fmt=\"3d\",  # Format numbers to 2 decimal places\n",
    "    cmap=\"magma\",  # Color scheme (colorblind-friendly: \"coolwarm\", \"viridis\")\n",
    "    linewidths=0.5,  # Thin lines for separation\n",
    "    linecolor=\"black\",  # Subtle black grid lines\n",
    "    cbar_kws={'shrink': 0.75, 'aspect': 30},  # Shrink color bar to fit\n",
    "    square=True,  # Keep cells square-shaped,\n",
    "    cbar=False,\n",
    "    annot_kws={\"size\": 14},\n",
    ")\n",
    "ax.set(yticklabels=[])\n",
    "\n",
    "# Improve label readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=14)  # Rotate x labels slightly\n",
    "plt.yticks(rotation=0, fontsize=14)  # Keep y labels horizontal\n",
    "\n",
    "# Adjust title and labels\n",
    "# plt.title(\"GIN\", fontsize=18, pad=10, fontweight=\"bold\")  # Add title\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(\"gin-heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sage = pd.read_csv(\"/results/from/evaluate/some/folder/sage.csv\", index_col=False)  # Change do DATA_DIR\n",
    "names = list(m_sage.iloc[:,0])\n",
    "index_mapper = {i : pretty_dataset_names_synt[j] for i,j in enumerate(names)}\n",
    "m_sage = m_sage.iloc[:, 1:]\n",
    "index_mapper_cols = {i : pretty_dataset_names_synt[i] for i in m_sage.columns}\n",
    "m_sage.rename(index=index_mapper, inplace=True)\n",
    "m_sage.rename(columns=index_mapper_cols, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    m_sage, \n",
    "    annot=True,  # Show values\n",
    "    fmt=\"3d\",  # Format numbers to 2 decimal places\n",
    "    cmap=\"magma\",  # Color scheme (colorblind-friendly: \"coolwarm\", \"viridis\")\n",
    "    linewidths=0.5,  # Thin lines for separation\n",
    "    linecolor=\"black\",  # Subtle black grid lines\n",
    "    cbar_kws={'shrink': 0.75, 'aspect': 30},  # Shrink color bar to fit\n",
    "    square=True,  # Keep cells square-shaped,\n",
    "    cbar=False,\n",
    "    annot_kws={\"size\": 14},\n",
    ")\n",
    "\n",
    "# Improve label readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=14)  # Rotate x labels slightly\n",
    "plt.yticks(rotation=0, fontsize=14)  # Keep y labels horizontal\n",
    "ax.set(yticklabels=[])\n",
    "\n",
    "# Adjust title and labels\n",
    "# plt.title(\"SAGE\", fontsize=18, pad=10, fontweight=\"bold\")  # Add title\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(\"sage-heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "choices = []\n",
    "valid_gens = [pretty_dataset_names_synt[n] for n in pretty_dataset_names_synt if \"nd\" in n]\n",
    "for i in valid_gens:\n",
    "    if m_sage[i][i] > m_gin[i][i]:\n",
    "        df.append(m_sage[i])\n",
    "        choices.append(\"sage\")\n",
    "    else:\n",
    "        df.append(m_gin[i])\n",
    "        choices.append(\"gin\")\n",
    "best_for_nd = pd.concat(df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    best_for_nd, \n",
    "    annot=True,  # Show values\n",
    "    fmt=\"3d\",  # Format numbers to 2 decimal places\n",
    "    cmap=\"magma\",  # Color scheme (colorblind-friendly: \"coolwarm\", \"viridis\")\n",
    "    linewidths=0.5,  # Thin lines for separation\n",
    "    linecolor=\"black\",  # Subtle black grid lines\n",
    "    cbar_kws={'shrink': 0.75, 'aspect': 30},  # Shrink color bar to fit\n",
    "    square=True,  # Keep cells square-shaped,\n",
    "    cbar=False,\n",
    "    annot_kws={\"size\": 14},\n",
    ")\n",
    "\n",
    "for label, tick, choice in zip(ax.get_xticklabels(), ax.get_xticks(), choices):\n",
    "    if choice == \"sage\":\n",
    "        label.set_color('r')\n",
    "    else:\n",
    "        label.set_color('b')\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=14)  # Rotate x labels slightly\n",
    "plt.yticks(rotation=0, fontsize=14)  # Keep y labels horizontal\n",
    "ax.set(yticklabels=[])\n",
    "\n",
    "# Adjust title and labels\n",
    "# plt.title(\"Best of GIN+SAGE\", fontsize=18, pad=10, fontweight=\"bold\")  # Add title\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(\"gin+sage-heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "def predict_res(dim):\n",
    "    coords = rng.normal(0, 1, size=dim)\n",
    "    norm = np.linalg.norm(coords)\n",
    "    coords /= norm\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_good_enough(y, y_p, perc=0.05, max_err=2):\n",
    "    sign_match = np.all((y <= 0) == (y_p <= 0)) or np.all((y >= 0) == (y_p >= 0))\n",
    "    \n",
    "    if not sign_match:\n",
    "        return sign_match\n",
    "    \n",
    "    return np.all(np.abs(y - y_p) <= max_err*perc)\n",
    "\n",
    "\n",
    "\n",
    "def count_corrects_for_model(results_model, perc, max_err=2):\n",
    "    gens = results_model[\"DatasetName\"].unique()\n",
    "\n",
    "    corr_per_model = {gen_name : [0, 0] for gen_name in gens}\n",
    "    \n",
    "    for name in tqdm(results_model[\"GraphName\"].unique()):\n",
    "        _results_model = results_model[results_model[\"GraphName\"] == name]\n",
    "        generator = _results_model.iloc[0][\"DatasetName\"]\n",
    "\n",
    "        true = _results_model[_results_model[\"Type\"] == \"True\"].to_numpy()[0][:-3]\n",
    "        pred = _results_model[_results_model[\"Type\"] == \"Pred\"].to_numpy()[0][:-3]\n",
    "        \n",
    "        is_good = prediction_good_enough(true, pred, perc, max_err)\n",
    "        if is_good:\n",
    "            corr_per_model[generator][0] += 1\n",
    "        else:\n",
    "            corr_per_model[generator][1] += 1\n",
    "\n",
    "    return corr_per_model\n",
    "\n",
    "correct_incorr_preds = []\n",
    "for model in dfs.keys():\n",
    "    print(model)\n",
    "    correct_incorr_preds.append([])\n",
    "    df = dfs[model]\n",
    "    model_name_clean = model.upper() if \"d_\" not in model else model.split(\"d_\")[1].upper()\n",
    "    for t in [0.05, 0.10, 0.25, 0.5]: #  np.arange(0.05, 0.5, 0.01)\n",
    "        corr = count_corrects_for_model(df, t)\n",
    "        d = pd.DataFrame.from_dict(corr).T\n",
    "        d.rename(columns={0: f\"{model.upper()}, C {t*100}%\", 1: f\"I {t*100}%\"}, inplace=True)\n",
    "        d.rename(index=(lambda x: f\"{pretty_dataset_names_synt[x]}\"), inplace=True)\n",
    "        correct_incorr_preds[-1].append(d)\n",
    "\n",
    "sage_correct = pd.concat(correct_incorr_preds[0], axis=1)\n",
    "gin_correct = pd.concat(correct_incorr_preds[1], axis=1)\n",
    "nd_correct = pd.concat([gin_correct, sage_correct], axis=1)\n",
    "\n",
    "d_correct = pd.concat(correct_incorr_preds[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(sage_correct.columns), 2):\n",
    "    print(sage_correct.columns[i])\n",
    "    _stats = sage_correct.iloc[:, i:i+2].sum()\n",
    "    corr = _stats.iloc[0]\n",
    "    incorr = _stats.iloc[1]\n",
    "    perc = np.round(corr/(corr+incorr)*100, 4)\n",
    "    print(f\"{perc}%\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "for i in range(0, len(gin_correct.columns), 2):\n",
    "    print(gin_correct.columns[i])\n",
    "    _stats = gin_correct.iloc[:, i:i+2].sum()\n",
    "    corr = _stats.iloc[0]\n",
    "    incorr = _stats.iloc[1]\n",
    "    print(f\"{np.round(corr/(corr+incorr)*100, 4)}%\")\n",
    "    print()\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "for i in range(0, len(d_correct.columns), 2):\n",
    "    print(d_correct.columns[i])\n",
    "    _stats = d_correct.iloc[:, i:i+2].sum()\n",
    "    corr = _stats.iloc[0]\n",
    "    incorr = _stats.iloc[1]\n",
    "    print(f\"{np.round(corr/(corr+incorr)*100, 4)}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_latex(df, caption=\"Table Caption\", label=\"tab:label\", column_format=None):\n",
    "    \"\"\"\n",
    "    Convert a Pandas DataFrame to a LaTeX table formatted in the academic style.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to convert.\n",
    "    - caption (str): Caption for the LaTeX table.\n",
    "    - label (str): Label for referencing in LaTeX.\n",
    "    - column_format (str, optional): Column alignment format (e.g., 'lccc' for left, center, center, center).\n",
    "\n",
    "    Returns:\n",
    "    - str: LaTeX table code.\n",
    "    \"\"\"\n",
    "    if column_format is None:\n",
    "        column_format = \"l\" + \"c\" * (len(df.columns))  # Default: all columns centered\n",
    "    \n",
    "    latex_str = df.to_latex(\n",
    "        index=True,  # Include index\n",
    "        escape=True,  # Prevent escaping LaTeX symbols\n",
    "        column_format=column_format,  # Align columns\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        bold_rows=False,  # Make index bold\n",
    "        longtable=False  # Use tabular instead of longtable\n",
    "    )\n",
    "\n",
    "    latex_str = latex_str.replace(r\"\\toprule\", r\"\\toprule\")  # Top rule\n",
    "    latex_str = latex_str.replace(r\"\\midrule\", r\"\\midrule\")  # Middle rule\n",
    "    latex_str = latex_str.replace(r\"\\bottomrule\", r\"\\bottomrule\")  # Bottom rule\n",
    "    \n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_to_latex(nd_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_to_latex(d_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions according to a simple random model\n",
    "m005 = 0\n",
    "m010 = 0\n",
    "m025 = 0\n",
    "m050 = 0\n",
    "\n",
    "for i in tqdm(range(int(1e6))):\n",
    "    y_2 = predict_res(2)\n",
    "    y_6 = predict_res(6)\n",
    "    y = np.hstack([y_2, y_6])\n",
    "\n",
    "    y_2_p = predict_res(2)\n",
    "    y_6_p = predict_res(6)\n",
    "    y_p = np.hstack([y_2_p, y_6_p])\n",
    "    \n",
    "    g005 = prediction_good_enough(y, y_p, perc=0.05)\n",
    "    g010 = prediction_good_enough(y, y_p, perc=0.1)\n",
    "    g025 = prediction_good_enough(y, y_p, perc=0.25)\n",
    "    g050 = prediction_good_enough(y, y_p, perc=0.5)\n",
    "\n",
    "    if g005:\n",
    "        m005 += 1\n",
    "    if g010:\n",
    "        m010 += 1\n",
    "    if g025:\n",
    "        m025 += 1\n",
    "    if g050:\n",
    "        m050 += 1\n",
    "\n",
    "print(f\"{np.round(m005/1e6*100, 4)}, {np.round(m010/1e6*100, 4)}, {np.round(m025/1e6*100, 4)}, {np.round(m050/1e6*100, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this you have to put arange(0.05,0.5,0.01) where [0.05,0.1,0.25,0.5] is placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def to_perc(col):\n",
    "    p = re.compile(r\"(\\d+\\.\\d+)\")\n",
    "    vals = []\n",
    "    for c in col:\n",
    "        val = np.round(float(p.search(c).group())/100, decimals=3)\n",
    "        vals.append(val)\n",
    "    return vals\n",
    "\n",
    "\n",
    "sage_corr_cols = [n for n in sage_correct.columns if \"SAGE, C\" in n]\n",
    "sage_just_corr = sage_correct.loc[:, sage_corr_cols]\n",
    "sage_just_corr.rename_axis(\"gens\", inplace=True)\n",
    "sage_just_corr.reset_index(inplace=True)\n",
    "sage_just_corr_melted = pd.melt(sage_just_corr, id_vars=[\"gens\"], value_vars=sage_corr_cols, var_name=\"Portion of Error\")\n",
    "sage_just_corr_melted[\"Type\"] = \"SAGE\"\n",
    "sage_just_corr_melted[\"Portion of Error\"] = to_perc(sage_just_corr_melted[\"Portion of Error\"])\n",
    "\n",
    "gin_corr_cols = [n for n in gin_correct.columns if \"GIN, C\" in n]\n",
    "gin_just_corr = gin_correct.loc[:, gin_corr_cols]\n",
    "gin_just_corr.rename_axis(\"gens\", inplace=True)\n",
    "gin_just_corr.reset_index(inplace=True)\n",
    "gin_just_corr_melted = pd.melt(gin_just_corr, id_vars=[\"gens\"], value_vars=gin_corr_cols, var_name=\"Portion of Error\")\n",
    "gin_just_corr_melted[\"Type\"] = \"GIN\"\n",
    "gin_just_corr_melted[\"Portion of Error\"] = to_perc(gin_just_corr_melted[\"Portion of Error\"])\n",
    "\n",
    "nd_just_corr = pd.concat([sage_just_corr_melted, gin_just_corr_melted], axis=0)\n",
    "\n",
    "d_correct_cols = [n for n in d_correct.columns if \"D_GIN, C\" in n]\n",
    "d_just_corr = d_correct.loc[:, d_correct_cols]\n",
    "d_just_corr.rename_axis(\"gens\", inplace=True)\n",
    "d_just_corr.reset_index(inplace=True)\n",
    "d_just_corr_melted = pd.melt(d_just_corr, id_vars=[\"gens\"], value_vars=d_correct_cols, var_name=\"Portion of Error\")\n",
    "d_just_corr_melted[\"Portion of Error\"] = to_perc(d_just_corr_melted[\"Portion of Error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_just_corr[\"Portion of Correct\"] = nd_just_corr.loc[:, [\"gens\", \"value\"]].apply(\n",
    "    lambda x: x[\"value\"] / 349, axis=1\n",
    ")\n",
    "d_just_corr_melted[\"Portion of Correct\"] = d_just_corr_melted.loc[\n",
    "    :, [\"gens\", \"value\"]\n",
    "].apply(lambda x: x[\"value\"] / 320 if x[\"gens\"] != \"Star\" else x[\"value\"] / 158, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=2.5)\n",
    "plt.rcParams.update({\"xtick.bottom\": True, \"ytick.left\": True})\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    nd_just_corr,\n",
    "    col=\"gens\",\n",
    "    hue=\"Type\",\n",
    "    col_wrap=6,\n",
    "    height=8,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    palette=['#006795', '#C04F17'],\n",
    "    # ylim=(0, 10)\n",
    ")\n",
    "g.map(\n",
    "    sns.lineplot,\n",
    "    \"Portion of Error\",\n",
    "    \"Portion of Correct\",\n",
    "    lw=5,\n",
    "    markers=True,\n",
    "    marker=\"o\",\n",
    "    markersize=10,\n",
    "    errorbar=None,\n",
    ")\n",
    "\n",
    "# minor_locator = ticker.AutoMinorLocator(50)\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.05))  # Major ticks every 10\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\")\n",
    "    # ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.0))\n",
    "    # ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'${x:.0f}'))  # Format major labels\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.10))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "\n",
    "    ax.tick_params(which=\"both\", direction=\"in\", length=6)  # Major and minor ticks\n",
    "    ax.tick_params(which=\"minor\", length=2, color=\"red\")  # Customize minor ticks\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_visible(True)\n",
    "    \n",
    "    for val,color in zip([0.5, 0.9], [\"orange\", \"green\"]):\n",
    "        ax.axhline(y=val, color=color, linestyle=\"--\", linewidth=2)  # Add horizontal line\n",
    "\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1) \n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "plt.legend()\n",
    "plt.savefig(\"detailed_correct.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=2.5)\n",
    "plt.rcParams.update({\"xtick.bottom\": True, \"ytick.left\": True})\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    d_just_corr_melted,\n",
    "    col=\"gens\",\n",
    "    col_wrap=6,\n",
    "    height=8,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    palette=['#006795', '#C04F17'],\n",
    "    # ylim=(0, 10)\n",
    ")\n",
    "g.map(\n",
    "    sns.lineplot,\n",
    "    \"Portion of Error\",\n",
    "    \"Portion of Correct\",\n",
    "    lw=5,\n",
    "    markers=True,\n",
    "    marker=\"o\",\n",
    "    markersize=10,\n",
    "    errorbar=None,\n",
    ")\n",
    "\n",
    "# minor_locator = ticker.AutoMinorLocator(50)\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.05))  # Major ticks every 10\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\")\n",
    "    # ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.0))\n",
    "    # ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'${x:.0f}'))  # Format major labels\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.10))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "\n",
    "    ax.tick_params(which=\"both\", direction=\"in\", length=6)  # Major and minor ticks\n",
    "    ax.tick_params(which=\"minor\", length=2, color=\"red\")  # Customize minor ticks\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_visible(True)\n",
    "    \n",
    "    for val,color in zip([0.4, 0.5, 0.9], [\"red\", \"orange\", \"green\"]):\n",
    "        ax.axhline(y=val, color=color, linestyle=\"--\", linewidth=2)  # Add horizontal line\n",
    "\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1) \n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "# plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(\"detailed_correct_d.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_of_truth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
