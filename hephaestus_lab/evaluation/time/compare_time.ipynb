{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"\\[INFO\\] ConstructLabels\\d+-\\d+-(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\")\n",
    "new_pattern_nd = re.compile(r\"\\[INFO\\] ConstructLabels_\\d{4}-\\d{2}-\\d{2}--\\d{2}:\\d{2}:\\d{2}\\.\\d+_\\d{1}-\\d+-(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\")\n",
    "\n",
    "pattern_name = re.compile(r\"(mlreal|sreal|for d| for nd)(\\w+)\")\n",
    "file_name_pattern = re.compile(r\"ConstructLabels\\d{1}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(lines, pattern_to_use):\n",
    "    start_date = re.search(pattern_to_use, lines[0]).groups()[0]\n",
    "    end_date  = re.search(pattern_to_use, lines[1]).groups()[0]\n",
    "    size, name = re.search(pattern_name, lines[0]).groups()\n",
    "\n",
    "    if \"for \" in size:\n",
    "        size = size.split(\"for \")[1]\n",
    "\n",
    "    start_date_time = datetime.datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_time = datetime.datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return [name, size, str(end_date_time-start_date_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in [\"d\", \"nd\", \"mlreal\", \"sreal\"]:\n",
    "    logs_path = Path(f\"../experiment_results/logger_raw/{dtype}/logger\")\n",
    "\n",
    "    time_data = []\n",
    "\n",
    "    for f in os.listdir(logs_path):\n",
    "        if \"ConstructLabels\" in f:\n",
    "            if file_name_pattern.search(f):\n",
    "                pattern_to_use = pattern\n",
    "            else:\n",
    "                pattern_to_use = new_pattern_nd\n",
    "\n",
    "            with open(logs_path / f, mode=\"r\", encoding=\"utf-8\") as fd:\n",
    "                lines = fd.readlines()\n",
    "                for i in range(0, len(lines), 4):\n",
    "                    time_data.append(get_info(lines[i:i+4], pattern_to_use))\n",
    "    \n",
    "    df = pd.DataFrame(time_data, columns=[\"Dataset\", \"Size\", \"Time\"])\n",
    "    df.to_csv(f\"{df['Size'][0]}-tLOPPED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the files resulting from the cells above in the folder that the `base_path` points to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../experiment_results/time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sreal_graphs = 56\n",
    "mlreal_graphs = 59\n",
    "nd_graphs = 3839\n",
    "d_graphs = 3840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrie_sreal_details = {\"cores_per_task\": 6, \"number_of_tasks\": 8}\n",
    "gtrie_mlreal_details = {\"cores_per_task\": 6, \"number_of_tasks\": 7}\n",
    "gtrie_d_details = {\n",
    "    \"cores_per_task\": 8,\n",
    "    \"number_of_tasks\": 6,\n",
    "}  # Despite higher count in config, effectively used 6 because of generator partition\n",
    "gtrie_nd_details = {\n",
    "    \"cores_per_task\": 8,\n",
    "    \"number_of_tasks\": 7,\n",
    "}  # Forest Fire and Random Geometric will be normalized to this amount of cores.\n",
    "model_details = {\"number_of_tasks\": 1, \"cores_per_task\": 5888}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for file in sorted(os.listdir(base_path)):\n",
    "    if \"mlreal-time\" in file:\n",
    "        dfs[\"mlreal\"] = pd.read_csv(base_path / file)\n",
    "    elif \"sreal-time\" in file:\n",
    "        dfs[\"sreal\"] = pd.read_csv(base_path / file)\n",
    "    elif \"nd-time\" in file:\n",
    "        dfs[\"nd\"] = pd.read_csv(base_path / file)\n",
    "    elif \"d-time\" in file:\n",
    "        dfs[\"d\"] = pd.read_csv(base_path / file)\n",
    "    else:\n",
    "        dfs[\"other\"] = pd.read_csv(base_path / file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dfs[\"nd\"].loc[:, \"Dataset\"] == \"FOREST_FIRE\"\n",
    "mask_rand_geom = dfs[\"nd\"].loc[:, \"Dataset\"] == \"LRANDOM_GEOMETRIC\"\n",
    "\n",
    "dfs[\"nd\"].loc[mask, \"Time\"] = pd.to_timedelta(dfs[\"nd\"][mask][\"Time\"]) * (\n",
    "    round(64 * 0.65) / 8\n",
    ")\n",
    "\n",
    "dfs[\"nd\"].loc[mask_rand_geom, \"Time\"] = pd.to_timedelta(\n",
    "    dfs[\"nd\"][mask_rand_geom][\"Time\"]\n",
    ") * (round(64 * 0.25) / 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$ tasks, each using $X_i$ time with $i \\in \\{1 \\dots N\\}$. Each tasks uses $K$ cores.\n",
    "\n",
    "$$\n",
    "\\text{Total Time Used} = \\sum_{i=1}^N X_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Total Core Time} = \\sum_{i=1}^N (KX_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Average Time per Core} = \\frac{1}{KN} \\sum_{i=1}^N (KX_i)  = \\frac{1}{N} \\cdot \\text{Total Time Used}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(times, details, cut_time=1):\n",
    "    total_elapsed_time = pd.to_timedelta(times).sum()\n",
    "    total_elapsed_time *= cut_time\n",
    "    total_core_time = total_elapsed_time*details[\"cores_per_task\"]\n",
    "    average_time_per_core = total_elapsed_time/details[\"number_of_tasks\"]\n",
    "    return total_elapsed_time, total_core_time, average_time_per_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_core_times = []\n",
    "total_core_times = []\n",
    "elapsed_times = []\n",
    "data_types = []\n",
    "model_types = []\n",
    "\n",
    "for d in [\"mlreal\", \"sreal\", \"d\", \"nd\"]:\n",
    "    for m in [\"gtrie\", \"gnn\"]:\n",
    "        cut_time = 1\n",
    "        times = dfs[d][\"Time\"]\n",
    "        details = eval(f\"gtrie_{d}_details\")\n",
    "\n",
    "        if m == \"gnn\":\n",
    "            times = [max(dfs[\"other\"][dfs[\"other\"][\"Size\"] == d][\"Time\"])]\n",
    "            details = model_details\n",
    "\n",
    "        if d == \"d\" or d == \"nd\":\n",
    "            cut_time = 0.1\n",
    "\n",
    "        elapsed, total_core, average_core = get_stats(times, details, cut_time=cut_time)\n",
    "\n",
    "        average_core_times.append(average_core)\n",
    "        total_core_times.append(total_core)\n",
    "        elapsed_times.append(elapsed)\n",
    "        data_types.append(d)\n",
    "        model_types.append(m)\n",
    "\n",
    "\n",
    "df_times = pd.DataFrame(\n",
    "    np.array([average_core_times, total_core_times, elapsed_times, data_types, model_types]),\n",
    ").transpose()\n",
    "df_times.columns = [\"AVG Core Time\", \"Total Core Time\", \"Elapsed\", \"Data Type\", \"Model Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can see that the *mlreal* (and *d*, *nd*) with GTrie has AVG Core time smaller than the elapsed time. This stems from aninefficient scheduling of the parallel tasks due to the very large size of some graphs in this category when compared to others, after all, the graphs go from medium to large :). There **was not** a more efficient way of scheduling this with this version of Gtrie. We could have used a more complex native parallel GTrie, but that would bring another set of difficulties. Hence, the result is still significant.\n",
    "\n",
    "\n",
    "For task A and task B:\n",
    "\n",
    "$$\n",
    "\\text{Speedup} = \\frac{\\text{Total Time Used}^{(A)}}{\\text{Total Time Used}^{(B)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Core Efficiency Gain} = \\frac{\\text{Total Core Time}^{(A)}}{\\text{Total Core Time}^{(B)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_mlreal = (\n",
    "    df_times[df_times[\"Data Type\"] == \"mlreal\"][\"Elapsed\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"mlreal\"][\"Elapsed\"].reset_index(drop=True)[1]\n",
    ")\n",
    "core_efficiency_gain_mlreal = (\n",
    "    df_times[df_times[\"Data Type\"] == \"mlreal\"][\"Total Core Time\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"mlreal\"][\"Total Core Time\"].reset_index(drop=True)[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_sreal = (\n",
    "    df_times[df_times[\"Data Type\"] == \"sreal\"][\"Elapsed\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"sreal\"][\"Elapsed\"].reset_index(drop=True)[1]\n",
    ")\n",
    "core_efficiency_gain_sreal = (\n",
    "    df_times[df_times[\"Data Type\"] == \"sreal\"][\"Total Core Time\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"sreal\"][\"Total Core Time\"].reset_index(drop=True)[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_d = (\n",
    "    df_times[df_times[\"Data Type\"] == \"d\"][\"Elapsed\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"d\"][\"Elapsed\"].reset_index(drop=True)[1]\n",
    ")\n",
    "core_efficiency_gain_d = (\n",
    "    df_times[df_times[\"Data Type\"] == \"d\"][\"Total Core Time\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"d\"][\"Total Core Time\"].reset_index(drop=True)[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_nd = (\n",
    "    df_times[df_times[\"Data Type\"] == \"nd\"][\"Elapsed\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"nd\"][\"Elapsed\"].reset_index(drop=True)[1]\n",
    ")\n",
    "core_efficiency_gain_nd = (\n",
    "    df_times[df_times[\"Data Type\"] == \"nd\"][\"Total Core Time\"].reset_index(drop=True)[0]\n",
    "    / df_times[df_times[\"Data Type\"] == \"nd\"][\"Total Core Time\"].reset_index(drop=True)[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_mlreal,core_efficiency_gain_mlreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_sreal,core_efficiency_gain_sreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_d,core_efficiency_gain_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_nd,core_efficiency_gain_nd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_of_truth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
